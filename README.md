# ScrapeSuite

**A modern, production-ready Python toolkit for web data extraction, transformation, and export.**

[![Python 3.12+](https://img.shields.io/badge/python-3.12+-blue.svg)](https://www.python.org/downloads/)
[![Tests](https://img.shields.io/badge/tests-197%20passing-success.svg)](./tests/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](./LICENSE)

---

## ğŸŒŸ Overview

ScrapeSuite combines **two powerful toolkits** for different web scraping workflows:

1. **ğŸ§™ Legacy Wizard Suite** - YAML-driven declarative scraping with interactive job generation
2. **âš’ï¸ Foundry Suite** - Modern command-line tools for extraction pipelines

Choose the approach that fits your workflow, or use both together!

---

## ğŸš€ Quick Start

```bash
# Clone and install
git clone https://github.com/russellbomer/scrapesuite.git
cd scrapesuite
pip install -r requirements.txt

# Option 1: Use the Wizard (guided scraper creation)
python -m scrapesuite.cli init

# Option 2: Use Foundry tools (command-line pipeline)
python -m scrapesuite.foundry probe https://example.com
```

**Requirements**: Python 3.12+

---

## âš’ï¸ Foundry Suite (v2.0)

A complete toolkit for building extraction pipelines with **5 integrated tools**:

### The 5 Tools

| Tool | Purpose | Usage |
|------|---------|-------|
| **ğŸ“¡ Probe** | Analyze HTML & detect patterns | `foundry probe <url\|file>` |
| **ğŸ“ Blueprint** | Design extraction schemas | `foundry blueprint create schema.yml` |
| **ğŸ”¨ Forge** | Execute data extraction | `foundry forge schema.yml --url <url>` |
| **âœ¨ Polish** | Transform & clean data | `foundry polish data.jsonl --dedupe` |
| **ğŸ“¦ Crate** | Export to multiple formats | `foundry crate data.jsonl output.csv` |

### Complete Pipeline Example

```bash
# 1. Analyze HTML structure
foundry probe https://example.com/blog --format json --output analysis.json

# 2. Design extraction schema
foundry blueprint create blog_schema.yml
# (Interactive editor opens - define containers & fields)

# 3. Preview extraction
foundry blueprint preview blog_schema.yml --file page.html

# 4. Execute extraction
foundry forge blog_schema.yml --url https://example.com/blog --output raw.jsonl

# 5. Clean & deduplicate
foundry polish raw.jsonl --dedupe --dedupe-keys title --output clean.jsonl

# 6. Export to CSV
foundry crate clean.jsonl blog_posts.csv
```

### Tool Features

**ğŸ” Probe** - HTML Analysis
- Framework detection (React, WordPress, Django, etc.)
- Container pattern finding with confidence scores
- Field suggestions based on HTML structure
- JSON/terminal output formats

**ğŸ“ Blueprint** - Schema Designer  
- Interactive schema builder with validation
- Live extraction preview
- Pydantic-based schema validation
- Pagination configuration support

**ğŸ”¨ Forge** - Extraction Engine
- Schema-driven extraction
- Built-in pagination support
- Rate limiting & robots.txt compliance
- JSONL streaming output

**âœ¨ Polish** - Data Transformation
- Deduplication (first/last strategies)
- 10+ built-in transformers (normalize_text, parse_date, extract_domain, etc.)
- Validation rules (email, URL, date, pattern matching)
- Field filtering & statistics

**ğŸ“¦ Crate** - Data Export
- CSV, JSON, SQLite exports
- Format auto-detection
- Custom table names & schema options
- PostgreSQL/MySQL ready (coming soon)

**ğŸ“š Detailed Foundry Documentation**: [docs/FOUNDRY_COMPLETE.md](docs/FOUNDRY_COMPLETE.md)

---

## ğŸ§™ Legacy Wizard Suite

Interactive, YAML-driven scraping with zero coding required.

### Key Features

**Interactive Wizard**
- Generate scrapers through guided prompts
- Automatic framework detection (9 frameworks)
- Smart selector suggestions
- Offline mode (paste HTML directly)

**YAML-Based Jobs**
- Declarative job definitions
- Reusable configurations
- Multiple output formats (Parquet, CSV, JSONL)
- Connector/transform/sink pipeline

**Framework-Aware Extraction**
- Detects: WordPress, Drupal, React, Vue, Next.js, Bootstrap, Tailwind, Shopify, Django
- 17+ field types (title, url, date, author, category, tags, rating, etc.)
- Framework-specific selector patterns
- Multi-framework site support

**State Management**
- SQLite-based cursor tracking
- Idempotent deduplication
- Failed URL recovery
- Batch tracking with timestamps

**Polite Scraping**
- Per-domain rate limiting (token bucket)
- Robots.txt parsing & caching (24h TTL)
- Exponential backoff with jitter
- Adaptive throttling (429/503 errors)

### Wizard Quick Start

```bash
# Launch interactive wizard
python -m scrapesuite.cli init

# The wizard will:
# 1. Ask for URL to scrape
# 2. Detect framework (WordPress, React, etc.)
# 3. Analyze HTML and suggest selectors
# 4. Let you pick containers & fields
# 5. Generate YAML job file

# Run generated job
python -m scrapesuite.cli run jobs/my_job.yml --live --max-items 20

# View state & results
python -m scrapesuite.cli state
```

### Example Job File

```yaml
id: blog_posts
connector:
  type: custom
  url: https://blog.example.com
  item_selector: article.post
  fields:
    - field: title
      selector: h2.entry-title
    - field: url
      selector: a.permalink::attr(href)
    - field: date
      selector: time.published::attr(datetime)
    - field: author
      selector: .author-name
  pagination:
    next_selector: a.next-page::attr(href)
    max_pages: 10

sink:
  type: parquet
  path: data/cache/blog_posts
```

**ğŸ“š Wizard Documentation**: [docs/WIZARD.md](docs/WIZARD.md)

---

## ğŸ“Š Project Statistics

**Status**: âœ… Production Ready

```
Total Tests:        197 (100% passing)
Total Code:         ~5,000 LOC
Tools:              5 Foundry + Legacy CLI
Export Formats:     CSV, JSON, SQLite, Parquet
Frameworks:         9 detected
Python Version:     3.12+
```

---

## ğŸ“ Project Structure

```
scrapesuite/
â”œâ”€â”€ scrapesuite/              # Main package
â”‚   â”œâ”€â”€ lib/                  # Foundation library
â”‚   â”‚   â”œâ”€â”€ http.py          # HTTP client with rate limiting
â”‚   â”‚   â”œâ”€â”€ ratelimit.py     # Token bucket rate limiter
â”‚   â”‚   â”œâ”€â”€ selectors.py     # CSS selector utilities
â”‚   â”‚   â”œâ”€â”€ robots.py        # Robots.txt parser
â”‚   â”‚   â””â”€â”€ policy.py        # Policy enforcement
â”‚   â”œâ”€â”€ tools/                # Foundry suite
â”‚   â”‚   â”œâ”€â”€ probe/           # HTML analysis tool
â”‚   â”‚   â”œâ”€â”€ blueprint/       # Schema designer
â”‚   â”‚   â”œâ”€â”€ forge/           # Extraction engine
â”‚   â”‚   â”œâ”€â”€ polish/          # Data transformation
â”‚   â”‚   â””â”€â”€ crate/           # Data export
â”‚   â”œâ”€â”€ framework_profiles/   # Framework detection
â”‚   â”œâ”€â”€ connectors/          # Data source connectors
â”‚   â”œâ”€â”€ transforms/          # Data transformations
â”‚   â”œâ”€â”€ sinks/               # Output writers
â”‚   â”œâ”€â”€ foundry.py           # Foundry CLI
â”‚   â”œâ”€â”€ cli.py               # Legacy CLI
â”‚   â”œâ”€â”€ wizard.py            # Interactive wizard
â”‚   â”œâ”€â”€ inspector.py         # HTML analysis
â”‚   â””â”€â”€ core.py              # Job runner
â”œâ”€â”€ tests/                    # Test suite (197 tests)
â”œâ”€â”€ docs/                     # Documentation
â”‚   â”œâ”€â”€ FOUNDRY_COMPLETE.md  # Foundry guide
â”‚   â”œâ”€â”€ WIZARD.md            # Wizard guide
â”‚   â”œâ”€â”€ FRAMEWORK_PROFILES.md
â”‚   â”œâ”€â”€ ARCHITECTURE_V2.md
â”‚   â”œâ”€â”€ TESTING.md
â”‚   â””â”€â”€ TROUBLESHOOTING.md
â”œâ”€â”€ examples/                 # Example job files
â””â”€â”€ scripts/                  # Utility scripts
```

---

## ğŸ“– Documentation

### User Guides
- **[Foundry Suite](docs/FOUNDRY.md)** - Complete guide to the 5 extraction tools
- **[Framework Profiles](docs/FRAMEWORK_PROFILES.md)** - Understanding framework detection
- **[Infinite Scroll API Guide](docs/INFINITE_SCROLL_API_GUIDE.md)** - Finding API endpoints for dynamic sites
- **[Troubleshooting](docs/TROUBLESHOOTING.md)** - Common issues and solutions

### Developer Guides
- **[Architecture](docs/ARCHITECTURE_V2.md)** - System design and structure
- **[Testing](docs/TESTING.md)** - Running and writing tests
- **[Security](docs/SECURITY.md)** - Bot evasion and best practices

### Quick Reference
- **[Examples](examples/jobs/)** - Pre-built job templates
- **[Contributing](CONTRIBUTING.md)** - How to contribute

---

## ğŸ§ª Development

### Running Tests

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=scrapesuite --cov-report=html

# Run specific tool tests
pytest tests/test_probe.py -v
pytest tests/test_forge.py -v
pytest tests/test_polish.py -v
pytest tests/test_crate.py -v

# Quick test
make test
```

### Code Quality

```bash
# Format code
make format

# Lint code  
make check

# Run all checks
make all
```

---

## ğŸ¤ Contributing

Contributions welcome! See [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

### Adding Framework Profiles

To add support for a new framework:

1. Create profile class in `framework_profiles/`
2. Implement detection with confidence scoring (0-100)
3. Add field mappings for common field types
4. Write tests with real-world HTML samples
5. Update documentation

Example:
```python
class AngularProfile(FrameworkProfile):
    name = "angular"
    
    @classmethod
    def detect(cls, html: str, item_element: Tag | None = None) -> int:
        score = 0
        if "ng-app" in html:
            score += 40
        if "ng-controller" in html:
            score += 30
        return min(score, 100)
```

---

## ğŸ—ºï¸ Roadmap

### Completed âœ…
- Foundry Suite (5 tools)
- Multi-framework detection
- 197 comprehensive tests
- Complete pipeline support
- CSV/JSON/SQLite exports

### In Progress ğŸš§
- PostgreSQL/MySQL exporters
- Cloud storage exports (S3, GCS)
- Performance optimization

### Planned ğŸ“‹
- API exports (REST, GraphQL)
- Web UI dashboard
- Docker deployment
- Scheduled extraction jobs
- PyPI packaging

---

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- [Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/) - HTML parsing
- [Pyarrow](https://arrow.apache.org/docs/python/) - Parquet output
- [Click](https://click.palletsprojects.com/) - CLI framework
- [Rich](https://rich.readthedocs.io/) - Terminal formatting
- [Pydantic](https://pydantic.dev/) - Data validation

---

## ğŸ“ Support

- **Documentation**: [docs/](docs/)
- **Examples**: [examples/jobs/](examples/jobs/)
- **Issues**: [GitHub Issues](https://github.com/russellbomer/scrapesuite/issues)

**Happy Scraping! ğŸ‰**
